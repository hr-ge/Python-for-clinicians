{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuEjfIyVvIuxGOP+45p8Bt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hr-ge/Python-for-clinicians/blob/main/exam_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this exam is to put together some of the core concepts we taught you along the course. In particular, you will work on a small data science project. Your task is to perform classification on the Iris dataset (https://archive.ics.uci.edu/dataset/53/iris) using the simplest machine learning algorithm: k-Nearest Neighbours (k-NN). You are expected to do a simple hypertuning optimization over the number of neighbours $k$ and implement more advanced training techniques such as k-Fold cross validation. You are NOT expected to write the code from scratch for the most part! Instead, you will have to fill in the blank spaces. Good luck!"
      ],
      "metadata": {
        "id": "EUN8mV8nid9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with a basic task from week 1. Print out your first and last name along with your position. Put the relevant code in the code cell below:"
      ],
      "metadata": {
        "id": "Z0AI5WFajev5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_5j9sdiW5i",
        "outputId": "95b3a7c7-97d5-44c6-d11e-6ee7485b4f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hristo Georgiev, PhD student\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now load a few familiar packages that we will need to use throughout the exam."
      ],
      "metadata": {
        "id": "LB5kcRcRjzis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "asuUWnA-j-cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now fetch the Iris dataset. For your convinience, we do that entirely through ```Python```, meaning that you do not have to worry about downloading a ```CSV``` file, mounting your drive, etc."
      ],
      "metadata": {
        "id": "1N0LotaZkap2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiwRmnrHky2x",
        "outputId": "ebb6ee7c-3209-4c39-a64f-7b97d79f3281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo"
      ],
      "metadata": {
        "id": "IXlYoMdUk4Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now for the actual fetching:"
      ],
      "metadata": {
        "id": "twGOMKwPk9WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "X = iris.data.features\n",
        "y = iris.data.targets"
      ],
      "metadata": {
        "id": "ClbEFvJIk_zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a pair of variables called ```X``` and ```y``` which supposedly stores the features and labels of the Iris dataset. Note, however, that we know nothing about their type. Are they a ```Pandas``` dataframe? Are they a ```NumPy``` array? Check the type of ```X``` and ```y``` by passing them as an argument to the ```type()```. Remember that arguments to a function are passed within the function's paranthesis. In this particular case, we should make two separate calls to the ```type()``` function. Fill in the blank space after the comas in the code cell below:"
      ],
      "metadata": {
        "id": "ENgaTPAjlHKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The type of X is: \", type(X))\n",
        "print(\"The type of y is: \", type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76zlaPoAlpzv",
        "outputId": "2cead999-02fc-41da-c247-84fe2325d89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of X is:  <class 'pandas.core.frame.DataFrame'>\n",
            "The type of y is:  <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If correct, your implementation should print out ```<class 'pandas.core.frame.DataFrame'>``` after the colon. We now know the type of ```X``` and ```y```. Unfortunately, this is not enough to understand the data. An experienced data scientist would always investigate further, as understanding the data is essential for solving the problem."
      ],
      "metadata": {
        "id": "mSifFnfcmhNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrYLrBLJnI79",
        "outputId": "a7d37703-16c9-416a-95be-5e691ab6fe33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focus on the first table. What can you tell about the data? How many distinct features can you count (see the table)? How many distinct classes are there (hint: use ```y.nunique()```)?"
      ],
      "metadata": {
        "id": "kO6FP119nVzd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmJv3PvQn6HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change # to the correct answer, for example, # -> 8:\n",
        "\n",
        "**There are # unique features and # unique classes in the dataset.**"
      ],
      "metadata": {
        "id": "aqdw5-Nnom6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we understand the data, it is time to do some basic preprocessing. Your task is to convert ```X``` and ```y``` from ```Pandas``` dataframes to ```NumPy``` arrays."
      ],
      "metadata": {
        "id": "P1Qh3nZWpiji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "93cKUqdMqBKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The type of X is: \", type(X))\n",
        "print(\"The type of y is: \", type(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALXUDjEqGZH",
        "outputId": "820dd4d1-add3-4561-e4e3-728c69493fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of X is:  <class 'numpy.ndarray'>\n",
            "The type of y is:  <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an aspiring data scientist, you should always be curious about the size of the data you are given. This is important mostly for computational reasons. Certain models are sufficiently good for smaller datasets, while others, such as neural networls (https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) excell when given a large dataset."
      ],
      "metadata": {
        "id": "8NX33qJeqL5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of X is: \", len(X))\n",
        "print(\"The size of y is: \", len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15SW34kfqvU3",
        "outputId": "d8469e91-2f2a-4025-d72c-b58bfead071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of X is:  150\n",
            "The size of y is:  150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why did I print the size of both ```X``` and ```y```? Are they not expected to match? The answer is yes. We can safely assume that the size of ```X``` and ```y``` matches in a well-established dataset, such as the Iris one. However, we often work with data that has not been pre-processed and normilized. If a single ```X``` sample was unlabelled (the respecting ```y``` was missing), we would have had a violation of the assumption of supervised learning that the data is labelled. Therefore, we would have needed to drop the unlabelled sample."
      ],
      "metadata": {
        "id": "46M1o7Vvq3qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall now look into the training setting. We will perform basic k-Fold Cross validation, and we will set $k$ to be $3$, meaning that at each step, we will train on $100$ samples and evaluate on $50$ samples. We will set the number of neighbours $n \\in [3, 5, 7]$ (we use $n$ to distinguish from $k$). We will use accuracy as our performance measure. For each number of neighbours $n$, we will define a model and train it on $3$ distinct data splits. We will then calculate and store the average accuracy."
      ],
      "metadata": {
        "id": "bfKO6pg4slzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now import some relevant machine learning stuff:"
      ],
      "metadata": {
        "id": "8XpB1jq1wVOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier # Import the k-NN classifier."
      ],
      "metadata": {
        "id": "M6kl4cefusvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the ```folds``` and ```neighbours``` variables accordingly."
      ],
      "metadata": {
        "id": "IbmXnCYtwV_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds      =\n",
        "neighbours ="
      ],
      "metadata": {
        "id": "Qu58lVx7veQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up 3-fold cross-validation:\n",
        "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Store average accuracies:\n",
        "average_accuracies = {}\n",
        "\n",
        "# Evaluate each value of n_neighbors:\n",
        "for n in neighbours:\n",
        "    accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Create and train k-NN model:\n",
        "        model = KNeighborsClassifier(n_neighbors=n)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict and evaluate:\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    # Store average accuracy for this n:\n",
        "    average_accuracies[n] = np.mean(accuracies)\n",
        "\n",
        "# Print results:\n",
        "for n in neighbours:\n",
        "    print(f\"n_neighbors = {n}: Average Accuracy = {average_accuracies[n]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVOzUHM4s-lQ",
        "outputId": "4f09ceb2-6a93-4b09-a331-77eab31de62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_neighbors = 3: Average Accuracy = 0.9600\n",
            "n_neighbors = 5: Average Accuracy = 0.9667\n",
            "n_neighbors = 7: Average Accuracy = 0.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Briefly explain which of the three classifiers would you choose and why. Think about not only accuracy but computational effectiveness as well."
      ],
      "metadata": {
        "id": "cwIIRe3iwinQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d1zFX6tBwuCa"
      }
    }
  ]
}